{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Paper Segmentation \n",
    "\n",
    "*CS445 Computational Photography Final Project*\n",
    "\n",
    "- Bruno Seo (sbseo2)\n",
    "- Michal Gryga (mgryga2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "- https://blog.francium.tech/object-detection-with-faster-rcnn-bc2e4295bf49\n",
    "- https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colab Setting\n",
    "\n",
    "- Run this chunk to download `paper dataset`\n",
    "- Change runtime type to `GPU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://uofi.box.com/shared/static/zaer1y9ob4lnb9r1sihmyp5pyivmbrop.zip -O paper_dataset.zip\n",
    "# !unzip paper_dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Data Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = './paper_dataset/img/'\n",
    "csv_dir = './paper_dataset/csv/' \n",
    "tst_dir = './tst/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaperDataset(object):\n",
    "    def __init__(self, img_dir, csv_dir):\n",
    "               \n",
    "        self.img_dic = defaultdict()\n",
    "        self.csv_dic = defaultdict()\n",
    "        \n",
    "        im_list = os.listdir(img_dir)\n",
    "        self.num_images = len(im_list)\n",
    "\n",
    "        for i in range(1,self.num_images+1):\n",
    "            im = cv2.imread(img_dir+'{}.jpg'.format(i))/255.0\n",
    "            im = im.astype('float32')\n",
    "            self.img_dic[i-1] = cv2.resize(im, (int(im.shape[1]), int(im.shape[0])))\n",
    "\n",
    "        for i in range(1,self.num_images+1):\n",
    "            self.csv_dic[i-1] = pd.read_csv(csv_dir+'{}.csv'.format(i))\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        im = self.img_dic[idx]\n",
    "        csv = self.csv_dic[idx]\n",
    "        \"\"\" Parameters \"\"\"\n",
    "        names = ['title', 'author', 'abstract']\n",
    "        labels_dic = {'title': 1, 'author':2, 'abstract': 3}\n",
    "        \"\"\" End \"\"\"\n",
    "        \n",
    "        boxes = list()\n",
    "        labels = list()\n",
    "        num_objs = len(names)\n",
    "        \n",
    "        for name in names:\n",
    "            xmin = csv.loc[csv['name']==str(name)]['xmin'].to_numpy()[0]\n",
    "            xmax = csv.loc[csv['name']==str(name)]['xmax'].to_numpy()[0]\n",
    "            ymin = csv.loc[csv['name']==str(name)]['ymin'].to_numpy()[0]\n",
    "            ymax = csv.loc[csv['name']==str(name)]['ymax'].to_numpy()[0]\n",
    "            boxes.append([int(xmin), int(ymin), int(xmax), int(ymax)])\n",
    "            labels.append(labels_dic[name])\n",
    "\n",
    "        # convert everything into a torch.Tensor\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        # there are three classes\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "\n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd # background\n",
    "        img = torchvision.transforms.ToTensor()(im)\n",
    "        \n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Dataset\n",
    "train_dataset = PaperDataset(img_dir, csv_dir)\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets = next(iter(train_data_loader))\n",
    "images = list(image.to(device) for image in images)\n",
    "targets = [{k: v.to(device) for k, v in t.items()} for t in targets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check\n",
    "\n",
    "Check whether training set is properly created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = targets[0]['boxes'].cpu().numpy().astype(np.int32)\n",
    "img = images[0].permute(1,2,0).cpu().numpy().copy()\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "for box in boxes:\n",
    "    cv2.rectangle(img, (box[0], box[1]), (box[2], box[3]), (220,0,0),2)\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "- Define model here. We use. Faster-r-cnn as our baseline.\n",
    "- Please change `num_classes` if you training multiple classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4 # 1class(title) + background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'res' # Choose between resnet, efficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model == 'res':\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True, progress=True)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "elif model == 'eff':\n",
    "    from utils import effnet_create_model\n",
    "    model = effnet_create_model(num_classes)\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for images, targets in train_data_loader:\n",
    "        \n",
    "        images =list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            model.to(device)    \n",
    "        loss_dict = model(images, targets)\n",
    "        \n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        loss_value = losses.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if itr%50 == 0:\n",
    "            print(\"Iteration #{} loss: #{}\".format(itr, loss_value))\n",
    "            \n",
    "        itr += 1\n",
    "        \n",
    "#         lr_scheduler.step()\n",
    "        \n",
    "    print(\"Epoch #{} loss: {}\".format(epoch, loss_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model  (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'./model-{model}-epoch-{num_epochs}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Validate on testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(object):\n",
    "    def __init__(self, img_dir):\n",
    "        self.img_dic = defaultdict()\n",
    "        \n",
    "        im_list = os.listdir(img_dir)\n",
    "        self.num_images = len(im_list)\n",
    "        for i in range(1,self.num_images+1):\n",
    "            im = cv2.imread(img_dir+'{}.jpg'.format(i))/255.0\n",
    "            im = im.astype('float32')\n",
    "            self.img_dic[i-1] = cv2.resize(im, (int(im.shape[1]), int(im.shape[0])))\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        im = self.img_dic[idx]\n",
    "        img = torchvision.transforms.ToTensor()(im)\n",
    "        \n",
    "        return img, _\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(tst_dir)\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "test_data_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for i, (images, _) in enumerate(test_data_loader):\n",
    "    images = list(image.to(device) for image in images)\n",
    "    outputs = model(images)\n",
    "\n",
    "    idx = 0 # I do not know why this value should be 0\n",
    "    sample = images[idx].permute(1,2,0).cpu().numpy().copy()\n",
    "    boxes = outputs[idx]['boxes'].data.cpu().numpy()\n",
    "    scores = outputs[idx]['scores'].data.cpu().numpy()\n",
    "    labels = outputs[idx]['labels'].data.cpu().numpy()\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    path = list()\n",
    "    for lbl, _, box in sorted(list(zip(labels, scores, boxes)), key=lambda x: x[1], reverse=True):\n",
    "        if len(path) == 3:\n",
    "            break\n",
    "\n",
    "        if lbl not in path:\n",
    "            x_min, y_min = int(box[0]), int(box[1])\n",
    "            x_max, y_max = int(box[2]), int(box[3])\n",
    "        \n",
    "            cv2.rectangle(sample, (x_min, y_min), (x_max, y_max), (220,0,0),2)\n",
    "            \n",
    "            path.append(lbl)\n",
    "\n",
    "    plt.imshow(sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
